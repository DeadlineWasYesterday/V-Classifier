{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqUtils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV\n",
    "import scikitplot as skplt\n",
    "from sklearn import metrics\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['CAATCG', 'GGTA', 'GTTGA', 'CATACG', 'TGAT', 'GTCGAA', 'CCAATT', 'TGTCGA', 'GTTGAC', 'CGGTTA', 'CGATA', 'TAGCGT', 'AAAAAA', 'GGTTGA', 'AAAAA', 'CAAT', 'CGTCAA', 'CGGTAA', 'CGTTGA', 'CAAC', 'ACCAAT', 'TTGACG', 'TCAATC', 'GTTG', 'CAATTG', 'CGCAAT', 'GGTT', 'TTGTCG', 'TCAA', 'CCAAT', 'ATACGC', 'CGATAG', 'TTGA', 'CATCAA', 'GTTGAT', 'ATACGG', 'CGATC', 'GTTGGT', 'GATC', 'CCGATA', 'GTCAAT', 'CGATAA', 'CGCGTT', 'ATCGTA', 'TCGGTT', 'ATCAAC', 'ATTGG', 'TCGA', 'GCAATC', 'CAATCT', 'GCGTAC', 'TTCGAC', 'GGTTG', 'TCCAAT', 'CGTAGT', 'TTGCG', 'CGGTT', 'CGATTA', 'ACGGTT', 'ATCAAT', 'TTGCGC', 'CAATC', 'CGAT', 'GCGTTA', 'CCGTTA', 'TTGAC', 'CGTCGA', 'ATAGCG', 'GTTGAG', 'TATCCG', 'GGTAGT', 'CGTTGC', 'TCGGTA', 'TGGTT', 'AGGTTG', 'AGGAA', 'TCGAGT', 'TCAAT', 'ATAGGG', 'GTACGC', 'ACGCAA', 'GGTACG', 'TCCTG', 'CAGAG', 'TTGATG', 'GTCGAC', 'CGGTTG', 'ACATCG', 'CAGC', 'TTTTTT', 'GGTATG', 'TAGGGT', 'GGTTC', 'TGGTTC', 'CGCGTA', 'AACC', 'CTCGAT', 'AACGGT', 'ATCAA', 'TCCAAC', 'AAAATG', 'AAATG', 'GTTGT', 'GTCATA', 'TCAATT', 'ACAATC', 'AATAAA', 'AATTGG', 'ATCATA', 'GGCGTA', 'AAATAA', 'TCAAC', 'CTAACG', 'ACGATA', 'TCAACC', 'ACCGGT', 'CAGA', 'GCATAC', 'CTGTA', 'CGGTA', 'GTTGC', 'CTGT', 'ATTGGT', 'GGTCAA', 'CGTA', 'GTCAA', 'TCGCAA', 'AGCTG', 'ATGGTA', 'CGCAA', 'GTCAAA', 'GATTGG', 'CTGGA', 'TTCGCA', 'ATCCAA', 'AACCGA', 'CCGCAA', 'GTCGA', 'TAACAC', 'TTTTTA', 'ATAACG', 'TATGGT', 'TTGGCG', 'TGGT', 'TCCAT', 'CAATT', 'GCGTAA', 'TCGT', 'CCGTAA', 'GGGTTA', 'CAATTA', 'AGCCT', 'TAGCGA', 'TACCAC', 'CGCAAA', 'ATATCG', 'CTGCA', 'CGTACC', 'ATCGGT', 'TCGATA', 'TCGTTG', 'TTGGT', 'CGACCA', 'GAAGA', 'GT', 'CTGAG', 'ATGCGA', 'CAG', 'GGTAC', 'GGTTGT', 'CCATAC', 'GTTGCG', 'GATAGG', 'GAT', 'CAA', 'CATACC', 'AACCGT', 'TTGCGA', 'CGTAT', 'CGTAAT', 'CGATGT', 'TTCCT', 'AC', 'CGATCG', 'CGCTAA', 'CACAAC', 'TACC', 'TTGAG', 'CCAATC', 'TATGCG', 'TATCG', 'AGCAG', 'GGTAG', 'TCGTAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [f for f in l if len(f) < 6]\n",
    "b = [f for f in l if len(f) == 6]\n",
    "b1 = [f for f in b if f[0] == 'A' or f[0] == 'T']\n",
    "b2 = [f for f in b if f[0] == 'G' or f[0] == 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "fet68 = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([pd.read_csv('../ppnnw5.csv')[['Gen', 'die', 'Fam'] + c], \n",
    "                 pd.read_csv('../ppnnw6.csv')[b]], axis = 1)\n",
    "\n",
    "df1 = df1.loc[df1['die'] == 'no']\n",
    "#df1 = pd.concat([df1[df1['Gen'] == 'ssRNA(-)'], df1[df1['Gen'] == 'ssRNA(-)g']],\n",
    "#               axis = 0).reset_index(drop = True)\n",
    "df1['Gen'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1t = pd.read_csv('../rnavtr2kup scored ls')\n",
    "df1t['Gen'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, df1t], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([pd.read_csv('../h1w5.csv')[['die'] + c], \n",
    "                 pd.read_csv('../h1w6p1.csv')[b1],\n",
    "                 pd.read_csv('../h1w6p2.csv')[b2]], axis = 1)\n",
    "#df2 = df2.loc[df2['die'] == 'no']\n",
    "df2['Gen'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../first5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.iloc[:, 2:].div(df2['Len'], axis = 0)\n",
    "df2['Len'] = 0\n",
    "df1['Len'] = df1['Gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df1[df2.columns], df2], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('../ppnnsk.csv')[['Gen', 'die']]\n",
    "# df1 = pd.concat([df1, pd.read_csv('../ppnnw5.csv')[['AATCG', 'ACGAT', 'ATACG', 'ATC', 'ATCA', 'ATCG', 'ATCGA', 'ATTCG', \n",
    "#                                                   'CAAT', 'CAATC', 'CGAAT', 'CGAT', 'CGATA', 'CGATC', 'CGATT', 'CGTA', \n",
    "#                                                   'GAT', 'GATC', 'GTCAA', 'TATCG', 'TCAA', 'TCAAT', 'TCGA', 'TCGAT', 'TCGTA', \n",
    "#                                                   'TGAT']], \n",
    "#                  pd.read_csv('../ppnnw6.csv')[['ACGATA', 'ATATCG', 'ATCGAT', 'CAATCG', 'CAATTG', 'CCGATA', 'CGATAA', \n",
    "#                                                'CGATAC', 'CGATAG', 'CGATAT', 'CGATCA', 'CGATTA', 'CGATTG', 'CGCATA', \n",
    "#                                                'CGGTAT', 'GTCGAT', 'GTCGTA', 'GTTGAT', 'TAATCG', 'TAGTCG', 'TCAATC', 'TCGATA', \n",
    "#                                                'TCGATC', 'TCGGTA']]], axis = 1)\n",
    "# df1 = df1.loc[df1['die'] == 'no']\n",
    "# df1['Gen'] = 1\n",
    "# df2 = pd.read_csv('../h1sk.csv')[['die']]\n",
    "# df2 = pd.concat([df2, pd.read_csv('../h1w5.csv')[['AATCG', 'ACGAT', 'ATACG', 'ATC', 'ATCA', 'ATCG', 'ATCGA', 'ATTCG', \n",
    "#                                                   'CAAT', 'CAATC', 'CGAAT', 'CGAT', 'CGATA', 'CGATC', 'CGATT', 'CGTA', \n",
    "#                                                   'GAT', 'GATC', 'GTCAA', 'TATCG', 'TCAA', 'TCAAT', 'TCGA', 'TCGAT', 'TCGTA', \n",
    "#                                                   'TGAT']], \n",
    "#                  pd.read_csv('../h1w6p1.csv')[['ACGATA', 'ATATCG', 'ATCGAT', 'TAATCG', \n",
    "#                                                'TAGTCG', 'TCAATC', 'TCGATA', 'TCGATC', 'TCGGTA']],\n",
    "#                  pd.read_csv('../h1w6p2.csv')[['CAATCG', 'CAATTG', 'CCGATA', 'CGATAA', 'CGATAC', 'CGATAG', 'CGATAT', 'CGATCA', \n",
    "#                                                'CGATTA', 'CGATTG', 'CGCATA', 'CGGTAT', 'GTCGAT', 'GTCGTA', 'GTTGAT']]], axis = 1)\n",
    "# df2 = df2.loc[df2['die'] == 'no']\n",
    "# df2['Gen'] = 0\n",
    "\n",
    "data = pd.concat([df1,df2], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting features and labels\n",
    "X_train = data.iloc[:, 1:].values.astype(float)\n",
    "y_train = data.iloc[:, 0].values.astype(float)\n",
    "\n",
    "X_test = ebv3[data.iloc[:,1:].columns].values.astype(float)\n",
    "y_test = ebv3.iloc[:, -1].values.astype(float)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 280, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#cv_bin = cross_val_score(classifier, X_train, y_train, cv=10, scoring='f1')\n",
    "#cv_mac = cross_val_score(classifier, X_train, y_train, cv=10, scoring='f1_macro')\n",
    "f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "f1mac = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "\n",
    "# dunnowhat = metrics.accuracy_score(y_test, y_pred)\n",
    "# y_pred_proba = classifier.predict_proba(X_test)[::,1]\n",
    "# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "# auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "# plt.legend(loc=4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122,   0],\n",
       "       [152,  40]], dtype=int64)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48049460118425635 0.3448275862068966\n"
     ]
    }
   ],
   "source": [
    "print(f1mac, f1bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebv3 = pd.read_csv('../pn nuc vs ebv3.fasta scored lab')#.drop(columns = 'Unnamed: 0')\n",
    "ebv3['Len'] = [len(s) for s in ebv3['1']]\n",
    "ebv3 = ebv3.drop(columns= ['1'])\n",
    "#ebv3 = ebv3[ebv3['Len'] >= 15000]\n",
    "gen = ebv3[\"Gen\"]\n",
    "ebv3 = ebv3.iloc[:,1:-1].div(ebv3['Len'], axis = 0)\n",
    "ebv3[\"Gen\"] = gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebv3.to_csv('../rnavtr2kup scored ls', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebv3 = pd.read_csv('../pn nuc vs ebv23.fasta scored lab')#.drop(columns = 'Unnamed: 0')\n",
    "ebv3['Len'] = [len(s) for s in ebv3['1']]\n",
    "ebv3 = ebv3[ebv3['Len'] >= 17000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ebv for msa', 'a') as f:\n",
    "    for i,r in ebv3.iterrows():\n",
    "        f.write('>%s\\n%s\\n' % (r['0'], r['1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "c = []\n",
    "for sr in SeqIO.parse('ebv for msa', 'fasta'):\n",
    "    c.append(sr.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13183\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def hamming_distance(chaine1, chaine2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(chaine1, chaine2))\n",
    "\n",
    "def hamming_distance2(chaine1, chaine2):\n",
    "    return len(list(filter(lambda x : ord(x[0])^ord(x[1]), zip(chaine1, chaine2))))\n",
    "\n",
    "if __name__==\"__main__\":    \n",
    "#     chaine1 = hashlib.md5(\"chaine1\".encode()).hexdigest()\n",
    "#     chaine2 = hashlib.md5(\"chaine2\".encode()).hexdigest()\n",
    "\n",
    "    chaine1 = c[0]\n",
    "    chaine2 = c[2]\n",
    "\n",
    "    #assert len(chaine1) == len(chaine2)\n",
    "\n",
    "    print(hamming_distance(chaine1, chaine2))\n",
    "\n",
    "    #print(hamming_distance2(chaine1, chaine2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
