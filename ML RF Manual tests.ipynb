{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqUtils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rfimp(feats,pnr):\n",
    "    \n",
    "    r = res[feats].copy()\n",
    "    pnr = pnr.drop(columns=['Id', 'MolTyp', 'Topol', 'Des'])\n",
    "\n",
    "    ps = pnr.loc[pnr['Gen'] == 1]\n",
    "    ns = pnr.loc[pnr['Gen'] == 0]\n",
    "\n",
    "    pnrs = pd.concat([ps,ns])\n",
    "    \n",
    "    #Splitting features and labels\n",
    "    X = pnrs.iloc[:, 3:].values.astype(float)\n",
    "    y = pnrs.iloc[:, 1].values.astype(float)\n",
    "    \n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Fitting Random Forest Classification to the Training set\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 15, criterion = 'entropy')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    dunnowhat = metrics.accuracy_score(y_test, y_pred)\n",
    "    cv_bin = cross_val_score(classifier, X, y, cv=5, scoring='f1')\n",
    "    cv_mac = cross_val_score(classifier, X, y, cv=5, scoring='f1_macro')\n",
    "    f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "    f1mac = f1_score(y_test, y_pred, average='macro')\n",
    "    return cv_bin, cv_mac, f1bin, f1mac, dunnowhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653658 0.07213781802967897\n",
      "0.9201008909653657\n"
     ]
    }
   ],
   "source": [
    "aclist = []\n",
    "\n",
    "for i in range(20):\n",
    "    fmac = whole(pnr)\n",
    "    aclist.append(fmac.mean())\n",
    "    print(fmac.mean(), fmac.std() *2)\n",
    "\n",
    "print(np.mean(aclist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection using SelectFromModel and RFECV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-02f2dcd67cd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m#cm = confusion_matrix(y_test, y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mcv_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mcv_mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "#selecting from res 340\n",
    "pn = pd.read_csv('pndf.csv')\n",
    "res = pd.read_csv('res 340.csv')\n",
    "pn.loc[pn['Gen'] == 'ssRNA(+)', 'Gen'] = 0\n",
    "pn.loc[pn['Gen'] == 'ssRNA(-)', 'Gen'] = 1\n",
    "\n",
    "fts = fdf.sort_values(by='final', ascending = False)[:50].index\n",
    "r = res[fts].copy()\n",
    "pnr = pd.concat([pn, r], axis = 1)\n",
    "pnr = pnr.drop(columns=['Id', 'MolTyp', 'Topol', 'Des', 'Len'])\n",
    "\n",
    "ps = pnr.loc[pnr['Gen'] == 1]\n",
    "ns = pnr.loc[pnr['Gen'] == 0]\n",
    "\n",
    "pnrs = pd.concat([ps,ns], axis = 0).reset_index(drop=True)\n",
    "\n",
    "#Splitting features and labels\n",
    "X = pnrs.iloc[:, 3:].values.astype(float)\n",
    "y = pnrs.iloc[:, 1].values.astype(float)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV\n",
    "#classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy')\n",
    "#classifier.fit(X_train, y_train)\n",
    "\n",
    "#feature selection 1\n",
    "selector1 = SelectFromModel(RandomForestClassifier(n_estimators = 20))\n",
    "selector1.fit(X_train, y_train)\n",
    "#feature selection 2\n",
    "selector2 = RFECV(RandomForestClassifier(n_estimators = 20), step=1, cv=5)\n",
    "selector2 = selector2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "#y_pred = sel.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cv_bin = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')\n",
    "cv_mac = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "f1mac = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Len', 'ATCA', 'ATCT', 'GCGT', 'TGGT', 'ATC', 'GTG', 'GATC', 'TATC',\n",
       "       'TCA', 'AATC', 'TCAT', 'TCAG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnrs.iloc[:, 3:].columns[(sel.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Len', 'ATCA', 'ATCT', 'GCGT', 'TGGT', 'ATC', 'GTG', 'GATC', 'TATC',\n",
       "       'TCA', 'GAT', 'CGCT', 'AGAT', 'CGT', 'TCAG', 'AGA', 'CACG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnrs.iloc[:, 3:].columns[(selector2.get_support())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting from lenc and tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "3140    0\n",
       "3141    0\n",
       "3142    0\n",
       "3143    0\n",
       "3144    0\n",
       "Name: Gen, Length: 3145, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnrs.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdf = pd.read_csv('../fdf2 win5.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "facs = fdf.sort_values(by= 'final', ascending = False)[:120].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#selecting for tps and res 340\n",
    "pn = pd.read_csv('pndf.csv')\n",
    "res = pd.read_csv('../win5.csv')\n",
    "pn.loc[pn['Gen'] == 'ssRNA(+)', 'Gen'] = 0\n",
    "pn.loc[pn['Gen'] == 'ssRNA(-)', 'Gen'] = 1\n",
    "\n",
    "fts = fdf.sort_values(by='result', ascending = False)[:120].index\n",
    "r = res[fts].copy()\n",
    "pnr = pd.concat([pn, r], axis = 1)\n",
    "\n",
    "ps = pnr.loc[pnr['Gen'] == 1]\n",
    "ns = pnr.loc[pnr['Gen'] == 0]\n",
    "\n",
    "pnrs = pd.concat([ps,ns], axis = 0).reset_index(drop=True)\n",
    "\n",
    "def tpfeatsel(pnrs):\n",
    "    \n",
    "    #Splitting features and labels\n",
    "    X = pnrs.iloc[:, -120:].values.astype(float)\n",
    "    y = pnrs.iloc[:, 5].values.astype(float)\n",
    "\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Fitting Random Forest Classification to the Training set\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    classifier = RandomForestClassifier(n_estimators = 20)\n",
    "    #classifier.fit(X_train, y_train)\n",
    "\n",
    "    #feature selection 1\n",
    "    selector1 = SelectFromModel(RandomForestClassifier(n_estimators = 20))\n",
    "    selector1.fit(X_train, y_train)\n",
    "    #feature selection 2\n",
    "    selector2 = RFECV(RandomForestClassifier(n_estimators = 20), step=1, cv=5)\n",
    "    selector2 = selector2.fit(X_train, y_train)\n",
    "\n",
    "    #Predicting the Test set results\n",
    "    #y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cv_bin = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')\n",
    "    cv_mac = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "    #f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "    #f1mac = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    return list(pnrs.iloc[:,-120:].columns[(selector2.get_support())]) + \\\n",
    "                list(pnrs.iloc[:,-120:].columns[(selector1.get_support())]), cv_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 iterations remain.\n",
      "18 iterations remain.\n",
      "17 iterations remain.\n",
      "16 iterations remain.\n",
      "15 iterations remain.\n",
      "14 iterations remain.\n",
      "13 iterations remain.\n",
      "12 iterations remain.\n",
      "11 iterations remain.\n",
      "10 iterations remain.\n",
      "9 iterations remain.\n",
      "8 iterations remain.\n",
      "7 iterations remain.\n",
      "6 iterations remain.\n",
      "5 iterations remain.\n",
      "4 iterations remain.\n",
      "3 iterations remain.\n",
      "2 iterations remain.\n",
      "1 iterations remain.\n",
      "0 iterations remain.\n"
     ]
    }
   ],
   "source": [
    "tfdf = pd.DataFrame(index = pnrs.iloc[:,-120:].columns, columns = ['count', 'mac'])\n",
    "tfdf['count'] = 0\n",
    "tfdf['mac'] = 0\n",
    "\n",
    "for i in range(20):\n",
    "    lit, mac = tpfeatsel(pnrs)\n",
    "    for f in lit:\n",
    "        tfdf.loc[f,'count'] = tfdf.loc[f,'count'] + 1\n",
    "        tfdf.loc[f,'mac'] = tfdf.loc[f,'mac'] + mac.mean()\n",
    "        \n",
    "    print('%d iterations remain.' % (19 - i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGATC', 'GGATC', 'GCGTT', 'GATCA', 'ACGTG', 'ATCAG', 'GATCT', 'ATCAT',\n",
       "       'CGCGT', 'ATCTC', 'ATATC', 'GTGGT', 'TCAGA', 'TGGTT', 'GCGTA', 'CACGT',\n",
       "       'TCATC', 'AGCGT', 'CGCTT', 'CGTGT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf.sort_values(by = 'count', ascending = False)[:20].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ATCA', 'ATC', 'ATCT', 'TATC', 'GATC', 'TCAG', 'TGGT', 'CGT', 'GCGT',\n",
       "       'CAGA', 'TCA', 'TCAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf.sort_values(by = 'count', ascending = False).index[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf['f1mac'] = tfdf['mac']/tfdf['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T to G', 'G to A', 'T to T', 'T to C', 'C to G', 'G to T', 'A to T',\n",
       "       'G to C', 'A to C'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf.sort_values(by = 'count', ascending = False).index[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A to A', 'A to T', 'A to G', 'A to C', 'T to A', 'T to T', 'T to G',\n",
       "       'T to C', 'G to A', 'G to T', 'G to G', 'G to C', 'C to G'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnrs.iloc[:,-16:].columns[(selector2.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A to T', 'T to T', 'T to G', 'T to C', 'G to A', 'G to T', 'G to C',\n",
       "       'C to G'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnrs.iloc[:,-16:].columns[(selector1.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
