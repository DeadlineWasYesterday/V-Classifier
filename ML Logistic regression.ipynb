{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classification\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('final file hopefully no errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fib2.cvs only\n",
    "\n",
    "dataset.loc[dataset['Gen'] == 'ssRNA(+)', 'Gen'] = 1\n",
    "dataset.loc[dataset['Gen'] == 'ssRNA(-)', 'Gen'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = dataset.loc[dataset['Gen'] == 1].reset_index()\n",
    "ns = dataset.loc[dataset['Gen'] == 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = pd.concat([ps,ns]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('res 340.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = res[['ATC', 'ATCA', 'ATCT', 'TGGT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnr = pd.concat([pn, r], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnr = pnr.drop(index = pnr.loc[pnr['MolTyp'] == 'DNA'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnr = pnr.drop(columns=['index', 'Id', 'MolTyp', 'Topol', 'Des'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pnr = pnr.rename(columns={'ATC' : 'E1', 'ATCA' : 'E2', 'ATCT' : 'E3', 'TGGT' : 'E4'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = pnr.loc[pnr['Gen'] == 1]\n",
    "ns = pnr.loc[pnr['Gen'] == 0]\n",
    "\n",
    "pnrs = pd.concat([ps,ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 1: length\n",
    "pnrs['F1'] = [len(i) for i in pnrs['Seq'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orf_translator function to find orfs and translate them\n",
    "\n",
    "#a = Seq(pnrs.loc[0,'Seq'], IUPAC.unambiguous_dna)\n",
    "#rec = SeqRecord(a)\n",
    "#table = 11\n",
    "#min_pro_len = 20\n",
    "\n",
    "def orf_translator(record, table, min_pro_len):\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "    for strand, nuc in [(+1, record.seq), (-1, record.seq.reverse_complement())]:\n",
    "        for frame in range(3):\n",
    "            length = 3 * ((len(record)-frame) // 3) #Multiple of three\n",
    "            for pro in nuc[frame:frame+length].translate(table).split(\"*\"):\n",
    "                if len(pro) >= min_pro_len:\n",
    "                    if strand == 1:\n",
    "                        s1.append(pro)\n",
    "                    else:\n",
    "                        s2.append(pro)\n",
    "    return s1,s2\n",
    "\n",
    "#orf_translator(rec, 11, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#feature 2: number of orfs on strand 1\n",
    "#feature 3: number of orfs in strand 2\n",
    "#feature 4: mean protein length on strand 1\n",
    "#feature 5: mean protein length on strand 2\n",
    "#feature 6: GC content\n",
    "#feature 7: no idea what this feature is\n",
    "\n",
    "f2, f3, f4, f5, f6, f7 = [],[],[],[],[],[]\n",
    "\n",
    "for i in pnrs['Seq'].to_list():\n",
    "    a = SeqRecord(Seq(i))\n",
    "    (s1, s2) = orf_translator(a, 11, 15)\n",
    "    f2.append(len(s1))\n",
    "    f3.append(len(s2))\n",
    "    \n",
    "pnrs['F2'] = f2\n",
    "pnrs['F3'] = f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting features and labels\n",
    "X = pnrs.iloc[:, 3:].values.astype(float)\n",
    "y = pnrs.iloc[:, 1].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training the Logistic Regression model on the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 62,  11],\n",
       "       [ 11, 701]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85        73\n",
      "         1.0       0.98      0.98      0.98       712\n",
      "\n",
      "    accuracy                           0.97       785\n",
      "   macro avg       0.92      0.92      0.92       785\n",
      "weighted avg       0.97      0.97      0.97       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3138.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030904</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>10988.525175</td>\n",
       "      <td>162.128107</td>\n",
       "      <td>232.636711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>7183.259646</td>\n",
       "      <td>96.097606</td>\n",
       "      <td>158.159160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.017545</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>1183.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.028220</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>7417.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.029582</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>7560.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.032595</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>11089.500000</td>\n",
       "      <td>173.750000</td>\n",
       "      <td>233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.054656</td>\n",
       "      <td>0.023478</td>\n",
       "      <td>0.020273</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>41178.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>927.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                E1           E2           E3           E4            F1  \\\n",
       "count  3138.000000  3138.000000  3138.000000  3138.000000   3138.000000   \n",
       "mean      0.030904     0.010100     0.008423     0.010541  10988.525175   \n",
       "std       0.004766     0.002466     0.001843     0.002493   7183.259646   \n",
       "min       0.017545     0.003667     0.003266     0.002627   1183.000000   \n",
       "25%       0.028220     0.008728     0.007427     0.009357   7417.000000   \n",
       "50%       0.029582     0.009667     0.008139     0.010283   7560.000000   \n",
       "75%       0.032595     0.011095     0.008983     0.011749  11089.500000   \n",
       "max       0.054656     0.023478     0.020273     0.020584  41178.000000   \n",
       "\n",
       "                F2           F3  \n",
       "count  3138.000000  3138.000000  \n",
       "mean    162.128107   232.636711  \n",
       "std      96.097606   158.159160  \n",
       "min      18.000000    24.000000  \n",
       "25%     112.000000   149.000000  \n",
       "50%     120.000000   164.000000  \n",
       "75%     173.750000   233.000000  \n",
       "max     482.000000   927.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnrs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
