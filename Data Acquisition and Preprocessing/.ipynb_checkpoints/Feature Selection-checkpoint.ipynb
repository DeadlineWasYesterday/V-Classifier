{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A total of 6 levels of feature selection is applied here:\n",
    "#1. The first tree-based selection\n",
    "#2. The first LASSO selection\n",
    "#3. The second tree-based selection from the first one\n",
    "#4. The second LASSO selection from the first one\n",
    "#5. The first tree-based selection leading into a LASSO selection\n",
    "#6. The first LASSO selection leading into a tree-based selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datafiles 'ppnn5', 'ppnn6' are virus dataframes containing both sequences of (+) and (-) RNA viruses as well as their reverse complements. 'h1w5', 'h1w6p1' and 'h1w6p2' are the dataframes of selected human transcripts.\n",
    "These dataframes all contain 5460 feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TRjLzMCkKQ1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import metrics\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df1 = pd.concat([pd.read_csv('ppnnw5.csv')[['Gen', 'die']], \n",
    "                 pd.read_csv('ppnnw5.csv').iloc[:,10:], \n",
    "                 pd.read_csv('ppnnw6.csv').iloc[:,10:]\n",
    "                ], axis = 1)\n",
    "df1 = df1.loc[df1['die'] == 'no']\n",
    "df1['Gen'] = 1\n",
    "\n",
    "df2 = pd.read_csv('h1sk.csv')[['die']]\n",
    "df2 = pd.concat([df2, \n",
    "                 pd.read_csv('h1w5.csv').iloc[:,5:], \n",
    "                 pd.read_csv('h1w6p1.csv').iloc[:,5:],\n",
    "                 pd.read_csv('h1w6p2.csv').iloc[:,5:]],\n",
    "                axis = 1)\n",
    "df2 = df2.loc[df2['die'] == 'no']\n",
    "df2['Gen'] = 0\n",
    "data = pd.concat([df1,df2], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrIqpieVkTOE"
   },
   "outputs": [],
   "source": [
    "#Splitting features and labels\n",
    "X = data.iloc[:, 2:].astype(float)\n",
    "y = data.iloc[:, 0].astype(float)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "X_train_nosc, X_test_nosc = X_train, X_test\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#feature selection 1\n",
    "selector1 = SelectFromModel(RandomForestClassifier(n_estimators = 200))\n",
    "selector1.fit(X_train, y_train)\n",
    "\n",
    "#evaluation\n",
    "rf1f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "rf1f1mac = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "824btbAgrtZE"
   },
   "outputs": [],
   "source": [
    "#save rf1\n",
    "a = list(X.columns[selector1.get_support()])\n",
    "with open('fs5/rf1', 'a') as f:\n",
    "    for feat in a:\n",
    "        f.write(feat)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "uTtvmcHYrUiG",
    "outputId": "c4ee39b1-9bf8-4e77-96f6-ebd54f93e0bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel1_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "sel1_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2cDrFhhtO-e"
   },
   "outputs": [],
   "source": [
    "#save ls1\n",
    "a = list(X.columns[sel1_.get_support()])\n",
    "with open('fs5/ls1', 'a') as f:\n",
    "    for feat in a:\n",
    "        f.write(feat)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLQ77zgppkR_"
   },
   "outputs": [],
   "source": [
    "#rf1 to rf2\n",
    "X_train_nosc2 = X_train_nosc.iloc[:, selector1.get_support()]\n",
    "X_test_nosc2 = X_test_nosc.iloc[:, selector1.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-a4gcTfqTC3"
   },
   "outputs": [],
   "source": [
    "#rf2\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train_nosc2)\n",
    "X_test = sc.transform(X_test_nosc2)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#feature selection 2\n",
    "selector2 = SelectFromModel(RandomForestClassifier(n_estimators = 200))\n",
    "selector2.fit(X_train, y_train)\n",
    "\n",
    "#evaluation\n",
    "rf2f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "rf2f1mac = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUhwL2qiuSHU"
   },
   "outputs": [],
   "source": [
    "#save rf2\n",
    "a = list(X_train_nosc.iloc[:, selector1.get_support()].columns[selector2.get_support()])\n",
    "with open('fs5/rf2', 'a') as f:\n",
    "    for feat in a:\n",
    "        f.write(feat)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "NWZBDR64u3cj",
    "outputId": "4b023e93-a19e-4b0e-c996-acdc0912de70",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ls2\n",
    "\n",
    "X_train_nosc2 = X_train_nosc.iloc[:, sel1_.get_support()]\n",
    "X_test_nosc2 = X_test_nosc.iloc[:, sel1_.get_support()]\n",
    "X_train = sc.fit_transform(X_train_nosc2)\n",
    "X_test = sc.transform(X_test_nosc2)\n",
    "\n",
    "sel2_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "sel2_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MAjyoVyvao7"
   },
   "outputs": [],
   "source": [
    "#save ls2\n",
    "a = list(X_train_nosc.iloc[:, sel1_.get_support()].columns[sel2_.get_support()])\n",
    "with open('fs5/ls2', 'a') as f:\n",
    "    for feat in a:\n",
    "        f.write(feat)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "mA6wJjWuvgbU",
    "outputId": "8eaec258-c146-4f27-c952-b405aa4e445a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf to ls\n",
    "X_train_nosc2 = X_train_nosc.iloc[:, selector1.get_support()]\n",
    "X_test_nosc2 = X_test_nosc.iloc[:, selector1.get_support()]\n",
    "X_train = sc.fit_transform(X_train_nosc2)\n",
    "X_test = sc.transform(X_test_nosc2)\n",
    "\n",
    "sel3_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "sel3_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heLr6H29v0oL"
   },
   "outputs": [],
   "source": [
    "#save rf to ls\n",
    "a = list(X_train_nosc.iloc[:, selector1.get_support()].columns[sel3_.get_support()])\n",
    "with open('fs5/rfls', 'a') as f:\n",
    "    for feat in a:\n",
    "        f.write(feat)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocAGc0RQviti"
   },
   "outputs": [],
   "source": [
    "#ls to rf\n",
    "X_train_nosc2 = X_train_nosc.iloc[:, sel1_.get_support()]\n",
    "X_test_nosc2 = X_test_nosc.iloc[:, sel1_.get_support()]\n",
    "X_train = sc.fit_transform(X_train_nosc2)\n",
    "X_test = sc.transform(X_test_nosc2)\n",
    "\n",
    "selector3 = SelectFromModel(RandomForestClassifier(n_estimators = 200))\n",
    "selector3.fit(X_train, y_train)\n",
    "\n",
    "rf2f1bin = f1_score(y_test, y_pred, average='binary')\n",
    "rf2f1mac = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0gR22bAwKEz"
   },
   "outputs": [],
   "source": [
    "#save ls to rf\n",
    "a = list(X_train_nosc.iloc[:, sel1_.get_support()].columns[selector3.get_support()])\n",
    "with open('fs5/lsrf', 'a') as f:\n",
    "    for feat in a:\n",
    "        f.write(feat)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaoKiZuX1GBq"
   },
   "outputs": [],
   "source": [
    "#save training and test set fractions\n",
    "pd.concat([X_train_nosc, y_train], axis = 1).to_csv('fs5/training fraction.csv')\n",
    "pd.concat([X_test_nosc, y_test], axis = 1).to_csv('fs5/testing fraction.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fs complete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
